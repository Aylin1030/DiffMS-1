
"""
DiffMS Modal Scaffold-Constrained Inference
æ”¯æŒéª¨æ¶çº¦æŸçš„ DiffMS æ¨ç†ï¼ˆåœ¨ Modal äº‘å¹³å°è¿è¡Œï¼‰
"""

import modal
from pathlib import Path

# åˆ›å»ºModal App
app = modal.App("diffms-scaffold-inference")

# DiffMSè·¯å¾„ï¼ˆæœ¬åœ°ï¼‰
DIFFMS_PATH = Path("/Users/aylin/yaolab_projects/diffms_yaolab/DiffMS")
DIFFMS_SRC_PATH = DIFFMS_PATH / "src"
DIFFMS_CONFIGS_PATH = DIFFMS_PATH / "configs"

# å®šä¹‰å®¹å™¨é•œåƒ - åŒ…å«DiffMSè¿è¡Œæ‰€éœ€çš„æ‰€æœ‰ä¾èµ–
image = (
    modal.Image.debian_slim(python_version="3.10")
    .apt_install(
        "git", "wget",
        "libxrender1", "libxext6", "libsm6", "libice6", "libx11-6", "libglib2.0-0"
    )
    .pip_install(
        "torch==2.0.1",
        "torchvision==0.15.2",
    )
    .pip_install(
        "torch-scatter==2.1.1",
        "torch-sparse==0.6.17",
    )
    .pip_install(
        "torch-geometric==2.3.1",
        "pytorch-lightning==2.0.0",
        "rdkit==2023.3.2",
        "pandas==2.0.3",
        "numpy==1.24.3",
        "hydra-core==1.3.2",
        "omegaconf==2.3.0",
        "tqdm==4.65.0",
        "h5py==3.9.0",
        "networkx==3.1",
        "wandb",
        "matplotlib",
        "seaborn",
    )
    .add_local_dir(str(DIFFMS_SRC_PATH), "/root/src")
    .add_local_dir(str(DIFFMS_CONFIGS_PATH), "/root/configs")
)

# åˆ›å»ºæŒä¹…åŒ–Volume
data_volume = modal.Volume.from_name("diffms-data", create_if_missing=True)
data_path = Path("/data")

model_volume = modal.Volume.from_name("diffms-models", create_if_missing=True)
model_path = Path("/models")

output_volume = modal.Volume.from_name("diffms-outputs", create_if_missing=True)
output_path = Path("/outputs")

stats_volume = modal.Volume.from_name("diffms-msg-stats", create_if_missing=True)
stats_path = Path("/msg_stats")

MINUTES = 60
HOURS = 60 * MINUTES


@app.function(
    image=image,
    volumes={
        str(data_path): data_volume,
        str(model_path): model_volume,
        str(output_path): output_volume,
        str(stats_path): stats_volume,
    },
    gpu="A100",
    timeout=4 * HOURS,
)
def run_scaffold_inference(
    scaffold_smiles: str,
    max_count: int = None,
    data_subdir: str = "processed_data",
    attachment_indices: str = None,
    enforce_scaffold: bool = True,
    use_rerank: bool = True
):
    """
    åœ¨Modaläº‘ç«¯è¿è¡Œéª¨æ¶çº¦æŸçš„DiffMSæ¨ç†
    
    Args:
        scaffold_smiles: éª¨æ¶çš„SMILESå­—ç¬¦ä¸²
        max_count: é™åˆ¶å¤„ç†çš„æ•°æ®ç‚¹æ•°é‡
        data_subdir: æ•°æ®å­ç›®å½•åç§°
        attachment_indices: é”šç‚¹ç´¢å¼•ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œå¦‚ "2,5,7"
        enforce_scaffold: æ˜¯å¦å¼ºåˆ¶è¦æ±‚åŒ…å«éª¨æ¶
        use_rerank: æ˜¯å¦å¯ç”¨è°±é‡æ’
    """
    import sys
    import os
    import logging
    from pathlib import Path
    import torch
    from pytorch_lightning import Trainer
    from pytorch_lightning.loggers import CSVLogger
    from omegaconf import DictConfig, OmegaConf
    
    # æ·»åŠ DiffMSæºä»£ç åˆ°Pythonè·¯å¾„
    diffms_src = Path("/root/src")
    sys.path.insert(0, str(diffms_src))
    os.chdir(str(diffms_src))
    
    # å¯¼å…¥DiffMSæ¨¡å—
    from src import utils
    from src.diffusion_model_spec2mol import Spec2MolDenoisingDiffusion
    from src.diffusion.extra_features import DummyExtraFeatures, ExtraFeatures
    from src.metrics.molecular_metrics_discrete import TrainMolecularMetricsDiscrete
    from src.diffusion.extra_features_molecular import ExtraMolecularFeatures
    from src.analysis.visualization import MolecularVisualization
    from src.datasets import spec2mol_dataset
    
    # å¯¼å…¥éª¨æ¶çº¦æŸå·¥å…·
    from src.inference.scaffold_hooks import smiles_to_mol, formula_of, formula_to_string
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)
    
    from rdkit import RDLogger
    RDLogger.DisableLog('rdApp.*')
    
    logger.info("=" * 80)
    logger.info("å¼€å§‹ DiffMS éª¨æ¶çº¦æŸæ¨ç† on Modal")
    logger.info("=" * 80)
    
    # éªŒè¯å’Œè§£æéª¨æ¶
    logger.info(f"\néª¨æ¶ä¿¡æ¯:")
    logger.info(f"  SMILES: {scaffold_smiles}")
    
    try:
        scaffold_mol = smiles_to_mol(scaffold_smiles)
        scaffold_formula = formula_of(scaffold_mol)
        scaffold_formula_str = formula_to_string(scaffold_formula)
        logger.info(f"  åˆ†å­å¼: {scaffold_formula_str}")
        logger.info(f"  é‡åŸå­æ•°: {scaffold_mol.GetNumAtoms()}")
        logger.info(f"  âœ“ éª¨æ¶éªŒè¯æˆåŠŸ")
    except Exception as e:
        logger.error(f"  âœ— éª¨æ¶SMILESæ— æ•ˆ: {e}")
        raise
    
    # æ˜¾ç¤ºé…ç½®
    logger.info(f"\næ¨ç†é…ç½®:")
    logger.info(f"  æ•°æ®è·¯å¾„: {data_path}")
    logger.info(f"  æ¨¡å‹è·¯å¾„: {model_path}")
    logger.info(f"  è¾“å‡ºè·¯å¾„: {output_path}")
    logger.info(f"  æ•°æ®å­ç›®å½•: {data_subdir}")
    logger.info(f"  GPUå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        logger.info(f"  GPUå‹å·: {torch.cuda.get_device_name(0)}")
    logger.info(f"  å¤„ç†æ•°æ®é‡: {'å…¨éƒ¨' if max_count is None else max_count}")
    logger.info(f"  é”šç‚¹ç´¢å¼•: {attachment_indices or 'æœªæŒ‡å®šï¼ˆå…è®¸æ‰€æœ‰ä½ç½®ï¼‰'}")
    logger.info(f"  å¼ºåˆ¶éª¨æ¶: {enforce_scaffold}")
    logger.info(f"  å¯ç”¨é‡æ’: {use_rerank}")
    
    # å®šä¹‰è·¯å¾„
    checkpoint_path = model_path / "diffms_msg.ckpt"
    processed_data_dir = data_path / data_subdir
    
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    if not processed_data_dir.exists():
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {processed_data_dir}")
    
    logger.info(f"\nâœ“ Checkpointæ–‡ä»¶: {checkpoint_path}")
    logger.info(f"âœ“ æ•°æ®ç›®å½•: {processed_data_dir}")
    
    # 1. ä»YAMLåŠ è½½é…ç½®
    logger.info("\næ­¥éª¤ 1: åŠ è½½é…ç½®...")
    from hydra import compose, initialize_config_dir
    
    config_dir = Path("/root/configs")
    
    with initialize_config_dir(config_dir=str(config_dir), version_base=None):
        cfg = compose(
            config_name="config",
            overrides=["dataset=msg"],
        )
    
    logger.info("âœ“ é…ç½®åŠ è½½æˆåŠŸ")
    
    # 2. ä¿®æ”¹é…ç½®ä¸ºéª¨æ¶çº¦æŸæ¨ç†æ¨¡å¼
    logger.info("\næ­¥éª¤ 2: é…ç½®éª¨æ¶çº¦æŸå‚æ•°...")
    
    OmegaConf.set_struct(cfg, False)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = {
        'split.tsv': processed_data_dir / 'split.tsv',
        'labels.tsv': processed_data_dir / 'labels.tsv',
        'spec_folder': processed_data_dir / 'spec_files',
        'subform_folder': processed_data_dir / 'subformulae' / 'default_subformulae',
    }
    
    for name, path in required_files.items():
        if not path.exists():
            raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦æ–‡ä»¶/ç›®å½•: {name} -> {path}")
        logger.info(f"  âœ“ {name}: {path}")
    
    # æ›´æ–°æ•°æ®é›†é…ç½®
    cfg.dataset.name = 'custom_data'
    cfg.dataset.datadir = str(processed_data_dir)
    cfg.dataset.split_file = str(required_files['split.tsv'])
    cfg.dataset.labels_file = str(required_files['labels.tsv'])
    cfg.dataset.spec_folder = str(required_files['spec_folder'])
    cfg.dataset.subform_folder = str(required_files['subform_folder'])
    cfg.dataset.stats_dir = str(stats_path)
    cfg.dataset.allow_none_smiles = True
    
    if max_count is not None:
        cfg.dataset.max_count = max_count
        logger.info(f"  âš  é™åˆ¶æµ‹è¯•æ•°æ®é‡: {max_count}")
    
    # æ¨ç†æ¨¡å¼é…ç½®
    cfg.general.test_only = True
    cfg.general.name = 'scaffold_inference'
    cfg.general.gpus = 1 if torch.cuda.is_available() else 0
    cfg.general.test_samples_to_generate = 10
    cfg.general.wandb = 'disabled'
    cfg.general.decoder = None
    cfg.general.encoder = None
    
    # ===== éª¨æ¶çº¦æŸé…ç½®ï¼ˆå…³é”®ï¼ï¼‰=====
    cfg.general.scaffold_smiles = scaffold_smiles
    cfg.general.attachment_indices = attachment_indices
    cfg.general.enforce_scaffold = enforce_scaffold
    cfg.general.use_rerank = use_rerank
    
    logger.info("\néª¨æ¶çº¦æŸé…ç½®:")
    logger.info(f"  scaffold_smiles: {cfg.general.scaffold_smiles}")
    logger.info(f"  attachment_indices: {cfg.general.attachment_indices}")
    logger.info(f"  enforce_scaffold: {cfg.general.enforce_scaffold}")
    logger.info(f"  use_rerank: {cfg.general.use_rerank}")
    
    # MSG Large Modelé…ç½®
    cfg.model.encoder_hidden_dim = 512
    cfg.model.encoder_magma_modulo = 2048
    
    logger.info("âœ“ é…ç½®ä¿®æ”¹å®Œæˆï¼ˆä½¿ç”¨MSG Large Model + éª¨æ¶çº¦æŸï¼‰")
    
    # 3. è¯»å–ç›®æ ‡åˆ†å­å¼å¹¶éªŒè¯
    logger.info("\næ­¥éª¤ 3: éªŒè¯éª¨æ¶ä¸ç›®æ ‡åˆ†å­å¼çš„å…¼å®¹æ€§...")
    
    import pandas as pd
    labels_df = pd.DataFrame(pd.read_csv(required_files['labels.tsv'], sep='\t'))
    
    logger.info(f"  æ€»å…± {len(labels_df)} ä¸ªè°±å›¾")
    
    # å¯¹æ¯ä¸ªæ ·æœ¬ï¼Œå°†ç›®æ ‡åˆ†å­å¼è®¾ç½®ä¸ºlabelsä¸­çš„formula
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿ target_formula åœ¨è¿è¡Œæ—¶åŠ¨æ€è®¾ç½®
    # æˆ‘ä»¬åœ¨é…ç½®ä¸­å…ˆä¸è®¾ç½®ï¼Œè®©æ¨¡å‹åœ¨test_stepä¸­è¯»å–
    logger.info("  å°†åœ¨æ¨ç†æ—¶ä¸ºæ¯ä¸ªæ ·æœ¬åŠ¨æ€è®¾ç½® target_formula")
    
    # æ£€æŸ¥éª¨æ¶æ˜¯å¦é€‚ç”¨äºè‡³å°‘ä¸€ä¸ªæ ·æœ¬
    from src.inference.scaffold_hooks import parse_formula, formula_subtract
    
    compatible_count = 0
    for idx, row in labels_df.iterrows():
        target_formula_str = row['formula']
        try:
            target_f = parse_formula(target_formula_str)
            delta_f = formula_subtract(target_f, scaffold_formula)
            compatible_count += 1
            logger.info(f"  âœ“ {row['spec']}: {target_formula_str} (Î”F = {formula_to_string(delta_f)})")
        except ValueError as e:
            logger.warning(f"  âœ— {row['spec']}: {target_formula_str} - éª¨æ¶è¿‡å¤§ï¼Œè·³è¿‡")
    
    if compatible_count == 0:
        logger.error("  âœ— éª¨æ¶ä¸æ‰€æœ‰æ ·æœ¬çš„åˆ†å­å¼éƒ½ä¸å…¼å®¹ï¼")
        logger.error(f"  éª¨æ¶åˆ†å­å¼: {scaffold_formula_str}")
        logger.error("  å»ºè®®ä½¿ç”¨æ›´å°çš„éª¨æ¶æˆ–æ£€æŸ¥åˆ†å­å¼")
        raise ValueError("éª¨æ¶ä¸æ‰€æœ‰ç›®æ ‡åˆ†å­å¼ä¸å…¼å®¹")
    
    logger.info(f"\n  âœ“ {compatible_count}/{len(labels_df)} ä¸ªæ ·æœ¬ä¸éª¨æ¶å…¼å®¹")
    
    # å°†labels DataFrameä¿å­˜åˆ°é…ç½®ä¸­ï¼Œä¾›åç»­ä½¿ç”¨
    # ï¼ˆå®é™…ä¸Šï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹ test_step æ¥è¯»å– formulaï¼‰
    
    # 4. åˆ›å»ºè¾“å‡ºç›®å½•
    logger.info("\næ­¥éª¤ 4: åˆ›å»ºè¾“å‡ºç›®å½•...")
    preds_dir = output_path / "predictions_scaffold"
    logs_dir = output_path / "logs_scaffold"
    smiles_dir = output_path / "smiles_scaffold"
    viz_dir = output_path / "visualizations_scaffold"
    
    preds_dir.mkdir(parents=True, exist_ok=True)
    logs_dir.mkdir(parents=True, exist_ok=True)
    smiles_dir.mkdir(parents=True, exist_ok=True)
    viz_dir.mkdir(parents=True, exist_ok=True)
    
    preds_pkl_dir = Path("/root/src/preds")
    preds_pkl_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"  âœ“ é¢„æµ‹è¾“å‡º: {preds_dir}")
    logger.info(f"  âœ“ SMILESè¾“å‡º: {smiles_dir}")
    logger.info(f"  âœ“ å¯è§†åŒ–: {viz_dir}")
    logger.info(f"  âœ“ æ—¥å¿—ç›®å½•: {logs_dir}")
    
    # 5-8. åˆ›å»ºæ•°æ®æ¨¡å—ã€æ¨¡å‹ç­‰ï¼ˆä¸åŸè„šæœ¬ç›¸åŒï¼‰
    logger.info("\næ­¥éª¤ 5-8: åˆ›å»ºæ•°æ®æ¨¡å—å’Œæ¨¡å‹...")
    
    try:
        datamodule = spec2mol_dataset.Spec2MolDataModule(cfg)
        dataset_infos = spec2mol_dataset.Spec2MolDatasetInfos(datamodule, cfg)
        
        # å›ºå®šç»´åº¦ï¼ˆMSGæ•°æ®é›†ï¼‰
        dataset_infos.input_dims = {'X': 16, 'E': 5, 'y': 2061}
        dataset_infos.output_dims = {'X': 8, 'E': 5, 'y': 2048}
        
        domain_features = ExtraMolecularFeatures(dataset_infos=dataset_infos)
        if cfg.model.extra_features is not None:
            extra_features = ExtraFeatures(cfg.model.extra_features, dataset_info=dataset_infos)
        else:
            extra_features = DummyExtraFeatures()
        
        train_metrics = TrainMolecularMetricsDiscrete(dataset_infos)
        visualization_tools = MolecularVisualization(cfg.dataset.remove_h, dataset_infos=dataset_infos)
        
        # åˆ›å»ºæ¨¡å‹
        model = Spec2MolDenoisingDiffusion(
            cfg=cfg,
            dataset_infos=dataset_infos,
            train_metrics=train_metrics,
            visualization_tools=visualization_tools,
            extra_features=extra_features,
            domain_features=domain_features
        )
        
        # åŠ è½½æƒé‡
        logger.info(f"  åŠ è½½checkpoint: {checkpoint_path}")
        checkpoint = torch.load(str(checkpoint_path), map_location='cpu')
        
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
            model.load_state_dict(state_dict, strict=True)
            logger.info("  âœ“ æƒé‡åŠ è½½æˆåŠŸ")
        else:
            model.load_state_dict(checkpoint, strict=True)
            logger.info("  âœ“ æƒé‡åŠ è½½æˆåŠŸ")
        
        logger.info("âœ“ æ¨¡å‹åˆ›å»ºå’Œæƒé‡åŠ è½½å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    # 9. åˆ›å»ºTrainer
    logger.info("\næ­¥éª¤ 9: åˆ›å»ºTrainer...")
    csv_logger = CSVLogger(str(logs_dir), name='scaffold_inference')
    
    use_gpu = cfg.general.gpus > 0 and torch.cuda.is_available()
    
    trainer = Trainer(
        accelerator='gpu' if use_gpu else 'cpu',
        devices=cfg.general.gpus if use_gpu else 1,
        logger=csv_logger,
        enable_progress_bar=True,
        enable_model_summary=False,
    )
    logger.info(f"âœ“ Traineråˆ›å»ºæˆåŠŸ (è®¾å¤‡: {'GPU' if use_gpu else 'CPU'})")
    
    # 10. è¿è¡Œæ¨ç†
    logger.info("\n" + "=" * 80)
    logger.info("æ­¥éª¤ 10: å¼€å§‹éª¨æ¶çº¦æŸæ¨ç†...")
    logger.info("=" * 80)
    
    try:
        trainer.test(model, datamodule=datamodule)
        logger.info("=" * 80)
        logger.info("âœ“ æ¨ç†å®Œæˆï¼")
        logger.info("=" * 80)
    except Exception as e:
        logger.error("=" * 80)
        logger.error(f"âœ— æ¨ç†å¤±è´¥: {e}")
        logger.error("=" * 80)
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    # 11. åå¤„ç†
    logger.info("\n" + "=" * 80)
    logger.info("æ­¥éª¤ 11: åå¤„ç† - è½¬æ¢å’Œå¯è§†åŒ–")
    logger.info("=" * 80)
    
    import shutil
    pkl_files = list(preds_pkl_dir.glob("*.pkl"))
    for pkl_file in pkl_files:
        dest = preds_dir / pkl_file.name
        shutil.copy2(pkl_file, dest)
        logger.info(f"  âœ“ å¤åˆ¶PKL: {pkl_file.name}")
    
    # è½¬æ¢ä¸ºSMILES
    logger.info("\n11.1 è½¬æ¢ä¸ºSMILES...")
    
    try:
        from rdkit import Chem
        import pandas as pd
        import pickle
        
        def mol_to_canonical_smiles(mol):
            if mol is None:
                return None
            try:
                Chem.RemoveStereochemistry(mol)
                smiles = Chem.MolToSmiles(mol, canonical=True)
                test_mol = Chem.MolFromSmiles(smiles)
                if test_mol is None:
                    return None
                return smiles
            except Exception:
                return None
        
        # åˆå¹¶æ‰€æœ‰pklæ–‡ä»¶
        all_predictions = []
        for pkl_file in sorted(pkl_files):
            logger.info(f"  å¤„ç†: {pkl_file.name}")
            with open(pkl_file, 'rb') as f:
                predictions = pickle.load(f)
                if isinstance(predictions, list):
                    all_predictions.extend(predictions)
        
        logger.info(f"  æ€»å…± {len(all_predictions)} ä¸ªè°±å›¾")
        
        # è½¬æ¢ä¸ºSMILESå¹¶éªŒè¯éª¨æ¶
        top1_data = []
        all_candidates_data = []
        valid_count = 0
        total_count = 0
        scaffold_match_count = 0
        
        for spec_idx, mol_list in enumerate(all_predictions):
            spec_id = f"spec_{spec_idx:04d}"
            
            if not isinstance(mol_list, list):
                mol_list = [mol_list]
            
            valid_smiles = []
            
            for rank, mol in enumerate(mol_list, start=1):
                total_count += 1
                smiles = mol_to_canonical_smiles(mol)
                
                if smiles is not None:
                    valid_count += 1
                    
                    # éªŒè¯æ˜¯å¦åŒ…å«éª¨æ¶
                    contains_scaf = False
                    if mol is not None:
                        try:
                            contains_scaf = mol.HasSubstructMatch(scaffold_mol)
                            if contains_scaf:
                                scaffold_match_count += 1
                        except:
                            pass
                    
                    valid_smiles.append(smiles)
                    all_candidates_data.append({
                        'spec_id': spec_id,
                        'rank': rank,
                        'smiles': smiles,
                        'contains_scaffold': contains_scaf
                    })
            
            # Top-1
            if valid_smiles:
                top1_data.append({'spec_id': spec_id, 'smiles': valid_smiles[0]})
            else:
                top1_data.append({'spec_id': spec_id, 'smiles': ''})
        
        # ä¿å­˜TSVæ–‡ä»¶
        top1_df = pd.DataFrame(top1_data)
        top1_file = smiles_dir / 'predictions_top1.tsv'
        top1_df.to_csv(top1_file, sep='\t', index=False)
        logger.info(f"  âœ“ Top-1é¢„æµ‹: {top1_file.name} ({len(top1_df)} è¡Œ)")
        
        all_candidates_df = pd.DataFrame(all_candidates_data)
        all_candidates_file = smiles_dir / 'predictions_all_candidates.tsv'
        all_candidates_df.to_csv(all_candidates_file, sep='\t', index=False)
        logger.info(f"  âœ“ æ‰€æœ‰å€™é€‰: {all_candidates_file.name} ({len(all_candidates_df)} è¡Œ)")
        
        logger.info(f"\n  ç»Ÿè®¡:")
        logger.info(f"    æœ‰æ•ˆSMILES: {valid_count}/{total_count} ({valid_count/total_count*100:.1f}%)")
        logger.info(f"    åŒ…å«éª¨æ¶: {scaffold_match_count}/{total_count} ({scaffold_match_count/total_count*100:.1f}%)")
        
    except Exception as e:
        logger.error(f"  âœ— SMILESè½¬æ¢å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    # å¯è§†åŒ–
    logger.info("\n11.2 ç”Ÿæˆå¯è§†åŒ–...")
    
    try:
        from rdkit.Chem import Draw
        
        # ç”ŸæˆTop-1å¯¹æ¯”å›¾
        valid_top1_mols = []
        valid_top1_legends = []
        
        for spec_idx, mol_list in enumerate(all_predictions[:20]):
            if not isinstance(mol_list, list):
                mol_list = [mol_list]
            
            if len(mol_list) > 0 and mol_list[0] is not None:
                smiles = mol_to_canonical_smiles(mol_list[0])
                if smiles:
                    valid_top1_mols.append(mol_list[0])
                    
                    # æ ‡è®°æ˜¯å¦åŒ…å«éª¨æ¶
                    has_scaf = ""
                    try:
                        if mol_list[0].HasSubstructMatch(scaffold_mol):
                            has_scaf = " âœ“"
                    except:
                        pass
                    
                    valid_top1_legends.append(f"Spec {spec_idx}{has_scaf}")
        
        if valid_top1_mols:
            top1_img = Draw.MolsToGridImage(
                valid_top1_mols,
                molsPerRow=5,
                subImgSize=(250, 250),
                legends=valid_top1_legends,
                returnPNG=False
            )
            top1_file = viz_dir / 'top1_comparison.png'
            top1_img.save(top1_file)
            logger.info(f"  âœ“ Top-1å¯¹æ¯”å›¾: {top1_file.name}")
        
        logger.info("âœ“ å¯è§†åŒ–å®Œæˆ")
        
    except Exception as e:
        logger.error(f"  âœ— å¯è§†åŒ–å¤±è´¥: {e}")
    
    # ä¿å­˜volume
    logger.info("\nä¿å­˜volumeæ›´æ–°...")
    output_volume.commit()
    logger.info("âœ“ Volumeæ›´æ–°å·²ä¿å­˜")
    
    logger.info("\n" + "=" * 80)
    logger.info("âœ… éª¨æ¶çº¦æŸæ¨ç†å…¨éƒ¨å®Œæˆï¼")
    logger.info("=" * 80)
    logger.info(f"\nç»“æœä¿å­˜åœ¨: {output_path}")
    logger.info(f"  - PKLæ–‡ä»¶: {preds_dir}")
    logger.info(f"  - SMILESæ–‡ä»¶: {smiles_dir}")
    logger.info(f"  - å¯è§†åŒ–: {viz_dir}")
    logger.info(f"  - æ—¥å¿—: {logs_dir}")
    
    return {
        "status": "success",
        "scaffold_smiles": scaffold_smiles,
        "scaffold_formula": scaffold_formula_str,
        "max_count": max_count,
        "gpu": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU",
        "total_spectra": len(all_predictions),
        "valid_smiles": valid_count,
        "scaffold_matches": scaffold_match_count,
        "total_candidates": total_count,
        "output_dirs": {
            "predictions": str(preds_dir),
            "smiles": str(smiles_dir),
            "visualizations": str(viz_dir),
            "logs": str(logs_dir)
        }
    }


@app.local_entrypoint()
def main(
    scaffold_smiles: str = "CC(=CCCC(C1CCC2(C1(CCC3=C2CCC4C3(CCC(C4(C)C)O)C)C)C)C(=O)O)C",
    max_count: int = 10,
    data_subdir: str = "test_top10",
    attachment_indices: str = None,
    enforce_scaffold: bool = True,
    use_rerank: bool = True
):
    """
    æœ¬åœ°å…¥å£ç‚¹ - ä»å‘½ä»¤è¡Œè°ƒç”¨
    
    ä½¿ç”¨æ–¹æ³•:
        # ä½¿ç”¨é»˜è®¤éª¨æ¶ï¼ˆä¸‰èœç±»åŒ–åˆç‰©ï¼‰
        modal run diffms_scaffold_inference.py
        
        # è‡ªå®šä¹‰éª¨æ¶
        modal run diffms_scaffold_inference.py --scaffold-smiles "c1ccccc1"
        
        # æŒ‡å®šé”šç‚¹
        modal run diffms_scaffold_inference.py --attachment-indices "2,5,7"
    """
    result = run_scaffold_inference.remote(
        scaffold_smiles=scaffold_smiles,
        max_count=max_count,
        data_subdir=data_subdir,
        attachment_indices=attachment_indices,
        enforce_scaffold=enforce_scaffold,
        use_rerank=use_rerank
    )
    
    print("\n" + "=" * 70)
    print("ğŸ‰ éª¨æ¶çº¦æŸæ¨ç†å®Œæˆï¼")
    print("=" * 70)
    print(f"çŠ¶æ€: {result['status']}")
    print(f"éª¨æ¶SMILES: {result['scaffold_smiles']}")
    print(f"éª¨æ¶åˆ†å­å¼: {result['scaffold_formula']}")
    print(f"æ•°æ®ç›®å½•: {data_subdir}")
    print(f"å¤„ç†æ•°æ®é‡: {result['max_count'] or 'å…¨éƒ¨'}")
    print(f"ä½¿ç”¨GPU: {result['gpu']}")
    print(f"\nç»“æœç»Ÿè®¡:")
    print(f"  æ€»è°±å›¾æ•°: {result['total_spectra']}")
    print(f"  æœ‰æ•ˆSMILES: {result['valid_smiles']}/{result['total_candidates']}")
    print(f"  åŒ…å«éª¨æ¶: {result['scaffold_matches']}/{result['total_candidates']}")
    print("=" * 70)
    print(f"\nğŸ“¥ ä¸‹è½½ç»“æœ:")
    print(f"  modal volume get diffms-outputs {output_path} ./scaffold_results")
    print()

